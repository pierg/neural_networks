# Configuration Eli
[E]
[E.structure]
layers = [
  { type = "Conv2D", filters = 32, kernel_size = [3, 1], activation = "relu" },
  { type = "Flatten" },
  { type = "Dense", units = 128, activation = "relu" },
  { type = "Dense", units = 128, activation = "relu" },
  { type = "Dense", units = 64, activation = "relu" },
  { type = "Dense", units = 32, activation = "linear" },
  { type = "Dense", units = 12, activation = "linear" },
]
[E.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["R_squared", "MeanSquaredError", "MeanAbsoluteError", "MeanAbsolutePercentageError", "RootMeanSquaredError"]
[E.dataset]
training = "dbig"
use_stats_of = 300000
[E.training]
epochs = 200



# Configuration A: Original CNN configuration
[A]
[A.structure]
layers = [
  { type = "Conv2D", filters = 32, kernel_size = [3, 1], activation = "relu" },
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Conv2D", filters = 64, kernel_size = [3, 1], activation = "relu" },
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Conv2D", filters = 128, kernel_size = [3, 1], activation = "relu" },
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Flatten" },
  { type = "Dense", units = 64, activation = "relu" },
  { type = "Dense", units = 128, activation = "relu" },
  { type = "Dense", units = 12, activation = "linear" },
]
[A.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["R_squared", "MeanSquaredError", "MeanAbsoluteError", "MeanAbsolutePercentageError", "RootMeanSquaredError"]
[A.dataset]
training = "dbig"
use_stats_of = 300000
[A.training]
epochs = 200



# Configuration P
[P]
[P.structure]
layers = [
  { type = "Conv2D", filters = 16, kernel_size = [3, 1], activation = "relu" },  # Reduced number of filters
  { type = "MaxPooling2D", pool_size = [2, 1] },
  # Removed one Conv2D and MaxPooling2D layer each to simplify the model
  { type = "Conv2D", filters = 32, kernel_size = [3, 1], activation = "relu" },  # Reduced number of filters
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Flatten" },
  { type = "Dense", units = 32, activation = "relu" },  # Reduced number of units
  # Removed one Dense layer to simplify the model
  { type = "Dense", units = 12, activation = "linear" },  # This is typically the output layer, kept as-is if it aligns with the number of desired outputs
]
[P.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["R_squared", "MeanSquaredError", "MeanAbsoluteError", "MeanAbsolutePercentageError", "RootMeanSquaredError"]
[P.dataset]
training = "dbig"
use_stats_of = 300000
[P.training]
epochs = 200


# Configuration P2
[P2]
[P2.structure]
layers = [
  { type = "Conv2D", filters = 64, kernel_size = [3, 1], activation = "relu" },
  { type = "Conv2D", filters = 64, kernel_size = [3, 1], activation = "relu" },  # Additional Conv2D layer
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Conv2D", filters = 128, kernel_size = [3, 1], activation = "relu" },
  { type = "Conv2D", filters = 128, kernel_size = [3, 1], activation = "relu" },  # Additional Conv2D layer
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Conv2D", filters = 256, kernel_size = [3, 1], activation = "relu" },
  { type = "Conv2D", filters = 256, kernel_size = [3, 1], activation = "relu" },  # Additional Conv2D layer
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Flatten" },
  { type = "Dense", units = 128, activation = "relu" },
  { type = "Dropout", rate = 0.5 },  # Dropout layer added to help prevent overfitting
  { type = "Dense", units = 256, activation = "relu" },
  { type = "Dropout", rate = 0.5 },  # Dropout layer added to help prevent overfitting
  { type = "Dense", units = 12, activation = "linear" },
]
[P2.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["R_squared", "MeanSquaredError", "MeanAbsoluteError", "MeanAbsolutePercentageError", "RootMeanSquaredError"]
[P2.dataset]
training = "dbig"
use_stats_of = 300000
[P2.training]
epochs = 200



# # Configuration PBN
# [PBN]
# [PBN.structure]
# layers = [
#   { type = "Conv2D", filters = 32, kernel_size = [3, 1], activation = "relu" },
#   { type = "BatchNormalization" },  # Added BatchNormalization
#   { type = "MaxPooling2D", pool_size = [2, 1] },
#   { type = "Conv2D", filters = 64, kernel_size = [3, 1], activation = "relu" },
#   { type = "BatchNormalization" },  # Added BatchNormalization
#   { type = "MaxPooling2D", pool_size = [2, 1] },
#   { type = "Conv2D", filters = 128, kernel_size = [3, 1], activation = "relu" },
#   { type = "BatchNormalization" },  # Added BatchNormalization
#   { type = "MaxPooling2D", pool_size = [2, 1] },
#   { type = "Flatten" },
#   { type = "Dense", units = 64, activation = "relu" },
#   { type = "BatchNormalization" },  # Added BatchNormalization before activation
#   { type = "Dense", units = 128, activation = "relu" },
#   { type = "BatchNormalization" },  # Added BatchNormalization before activation
#   { type = "Dense", units = 12, activation = "linear" },
# ]
# [PBN.compile]
# optimizer = "adam"
# loss = "mean_squared_error"
# metrics = ["R_squared", "MeanSquaredError", "MeanAbsoluteError", "MeanAbsolutePercentageError", "RootMeanSquaredError"]
# [PBN.dataset]
# training = "dbig"
# use_stats_of = 300000
# [PBN.training]
# epochs = 200