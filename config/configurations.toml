# Simplified Configuration S1
[S1]
[S1.structure]
layers = [
  { type = "Conv2D", filters = 8, kernel_size = [3, 1], activation = "relu" },  # Reduced filters
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Flatten" },
  { type = "Dense", units = 12, activation = "linear" },  # Output layer simplified
]
[S1.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["MeanSquaredError"]
[S1.dataset]
shuffle_buffer_size = 1024
batch_size = 32  # Reduced batch size
splits = [0.7, 0.15, 0.15]
[S1.training]
epochs = 3  # Keeping the same to ensure some level of training adequacy

# Simplified Configuration S2
[S2]
[S2.structure]
layers = [
  { type = "Conv2D", filters = 16, kernel_size = [3, 1], activation = "relu" },  # A bit more filters than S1
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Conv2D", filters = 8, kernel_size = [3, 1], activation = "relu" },  # Additional Conv2D, fewer filters
  { type = "MaxPooling2D", pool_size = [2, 1] },
  { type = "Flatten" },
  { type = "Dense", units = 12, activation = "linear" },  # Simple output layer
]
[S2.compile]
optimizer = "adam"
loss = "mean_squared_error"
metrics = ["MeanSquaredError"]
[S2.dataset]
shuffle_buffer_size = 1024
batch_size = 32  # Reduced batch size
splits = [0.7, 0.15, 0.15]
[S2.training]
epochs = 3
